from torch import nn
from model.blocks.SSIU import *
from model.blocks.CrossTrans import *
from model.blocks.LCAM import *
from model.blocks.MFFS import *
from model.blocks.CBAM import *
from model.blocks.CCAM import *
from model.blocks.EMA import *


class LCAFormer(nn.Module):
    def __init__(self, nclass):
        super(LCAFormer, self).__init__()
        self.nclass = nclass
        self.in_channels = [48, 96, 192, 384]
        self.dilation1 = 2
        self.dilation2 = 4
        self.dilation3 = 8

        self.stage1 = nn.Sequential(
            nn.Conv2d(in_channels=3, out_channels=self.in_channels[0], kernel_size=3, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(self.in_channels[0]),
            SSIU(self.in_channels[0], self.dilation1)
        ).cuda()

        self.stage2 = nn.Sequential(
            nn.Conv2d(in_channels=self.in_channels[0], out_channels=self.in_channels[1], kernel_size=3, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(self.in_channels[1]),
            SSIU(self.in_channels[1], self.dilation2)
        ).cuda()

        self.stage3 = nn.Sequential(
            nn.Conv2d(in_channels=self.in_channels[1], out_channels=self.in_channels[2], kernel_size=3, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(self.in_channels[2]),
            SSIU(self.in_channels[2], self.dilation3)
        ).cuda()

        self.stage4 = nn.Sequential(
            nn.Conv2d(in_channels=self.in_channels[2], out_channels=self.in_channels[3], kernel_size=3, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(self.in_channels[3]),
            CrossTrans(self.in_channels[3])
        ).cuda()


        self.LCAM1 = LCAM(dim=self.in_channels[0]).cuda()
        self.LCAM2 = LCAM(dim=self.in_channels[1]).cuda()
        self.LCAM3 = LCAM(dim=self.in_channels[2]).cuda()
        self.LCAM4 = LCAM(dim=self.in_channels[3]).cuda()

        self.MFFS1 = MFFS(self.in_channels[0], self.in_channels[1]).cuda()
        self.MFFS2 = MFFS(self.in_channels[1], self.in_channels[2]).cuda()
        self.MFFS3 = MFFS(self.in_channels[2], self.in_channels[3]).cuda()

        self.up = nn.Sequential(
            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
            nn.Conv2d(self.in_channels[0], self.nclass, kernel_size=1),
            nn.BatchNorm2d(self.nclass),
            nn.ReLU(inplace=True)
        ).cuda()

        self.fake = nn.Sequential(
            nn.Conv2d(self.nclass, 64, kernel_size=3, stride=2, padding=1, bias=False),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),

            nn.Conv2d(64, self.in_channels[0], kernel_size=1),
            nn.BatchNorm2d(self.in_channels[0]),
            nn.ReLU(inplace=True),

            nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True),
            nn.Conv2d(self.in_channels[0], 3, kernel_size=1),
            nn.BatchNorm2d(3),
            nn.ReLU(inplace=True)
        ).cuda()

    def forward(self, x):
        x = x.cuda()
        stage1 = self.stage1(x)
        stage2 = self.stage2(stage1)
        stage3 = self.stage3(stage2)
        stage4 = self.stage4(stage3)


        stage1 = self.LCAM1(stage1)
        stage2 = self.LCAM2(stage2)
        stage3 = self.LCAM3(stage3)
        stage4 = self.LCAM4(stage4)

        fusion3 = self.MFFS3(stage3, stage4)
        fusion2 = self.MFFS2(stage2, fusion3)
        fusion = self.MFFS1(stage1, fusion2)

        final = self.up(fusion)

        fake = self.fake(final)


        outputs = []

        outputs.append(final)
        return final


if __name__ == '__main__':
    model = LCAFormer(2)
    images = torch.randn(1, 3, 256, 256)
    with torch.no_grad():
        x = model.forward(images)
    print(x[0].shape)
    flops, params = profile(model, (images,))
    print('flops: %.2f GFLOPS, params: %.2f M' % (flops / 1000000000.0, params / 1000000.0))
